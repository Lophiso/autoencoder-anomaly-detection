{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "040ba236-cca3-40ef-8b1c-5ec8bb8ff013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: True\n",
      "Loaded data shape: (4894, 16)\n",
      "Filtered data shape (before windowing): (4894, 16)\n",
      "Windowed data shape: (194, 50, 15)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the merged and filtered CSV data\n",
    "\n",
    "DATA_PATH = r\"C:\\MLCourse\\My_Exercises\\Autonomous System\\Data\\filtered_sensor_data.csv\"\n",
    "\n",
    "def load_data(path=DATA_PATH):\n",
    "    \"\"\"\n",
    "    Load sensor data from the CSV file.\n",
    "    \"\"\"\n",
    "    print(\"File exists:\", os.path.exists(DATA_PATH))\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "\n",
    "# normalize sensor data to avoid one feature from overwhelming the other\n",
    "\n",
    "def normalize_data(df, method=\"minmax\"):\n",
    "    \"\"\"\n",
    "    Normalize sensor values using MinMax or Z-score.\n",
    "    \"\"\"\n",
    "\n",
    "    # Drop the 'Timestamp' column before normalization\n",
    "    \n",
    "    if 'timestamp' in df.columns:\n",
    "        df = df.drop(columns=['timestamp'])\n",
    "    if method == \"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled = scaler.fit_transform(df)\n",
    "    elif method == \"zscore\":\n",
    "        scaled = (df - df.mean()) / df.std()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported normalization method\")\n",
    "    return scaled     # this returns the NORMALIZED dataframe (sensor value)\n",
    "\n",
    "\n",
    "def segment_windows(data, window_size=50, step_size=25):\n",
    "    \"\"\"\n",
    "    Segment time-series data using sliding window.\n",
    "    Returns shape: [num_windows, window_size, num_features]\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    for start in range(0, len(data) - window_size + 1, step_size):\n",
    "        window = data[start:start+window_size]\n",
    "        windows.append(window)\n",
    "    return np.array(windows)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_data()\n",
    "    print(f\"Loaded data shape: {df.shape}\")\n",
    "    \n",
    "    data_norm = normalize_data(df)\n",
    "\n",
    "    print(\"Filtered data shape (before windowing):\", df.shape)\n",
    "\n",
    "    #        print(\"\\nüîç Sample of Normalized Data:\\n\")\n",
    "    #        print(pd.DataFrame(data_norm, columns=df.columns).head())  # visualize as DataFrame\n",
    "    \n",
    "    windows = segment_windows(data_norm)\n",
    "    print(f\"Windowed data shape: {windows.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f335304-31d1-47e6-b138-86472d424498",
   "metadata": {},
   "source": [
    "Sample windowed value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f869b-232a-446c-9dbc-d452ba4e4c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First window (shape):\", windows[0].shape)\n",
    "print(windows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97cc3a-9bbb-47dd-8262-057b4fc9d19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
